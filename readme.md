## Jigsaw Unintended Bias in Toxicity Classification
This was a kaggle competition organized by [Jigsaw](https://jigsaw.google.com/). The challenge was to build a model that recognizes toxicity in comments and minimizes bias towards the names of frequently attecked identities with toxicity. A labeled dataset was provided for identity mentions. The competition was `Kernels-only` and here I am showcasing my approach for data processing and designing a model to solve the challenge. <br>

[Competition Link](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview)

## Dependencies
- Numpy
- Pandas
- Seaborn
- NLTK
- Tensorflow

My Local environemnt packages are available in the `requirements.txt` file.

To install the same packages, run the command:
```python
pip install -r requirements.txt
```

## Author
**Name**: Sifat Ul Alam <br>
**Email**: sifatnabil@gmail.com <br>
[LinkedIn](https://www.linkedin.com/in/sifat-nabil-2a9b3078/) || [GitHub](https://github.com/sifatnabil) || [Kaggle](https://www.kaggle.com/sifatnabil)

## Acknowledgements
This repository was submitted as a project for Upskill's ISA IM Workshop.